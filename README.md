# Dremio Optimizer Agent

**AI-powered query optimization and performance analysis for Dremio**

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

An intelligent agent that automatically analyzes Dremio query performance, detects optimization opportunities, and generates actionable recommendations using AI. Supports both **Dremio Cloud** and **on-premises** deployments.

---

## ğŸ¯ What It Does

The Dremio Optimizer Agent:

1. **ğŸ“Š Collects** comprehensive data from Dremio (query history, execution profiles, metadata)
2. **ğŸ” Analyzes** performance using 6+ specialized detectors
3. **ğŸ¤– Recommends** optimizations via AI agent with reasoning and SQL rewrites
4. **ğŸ“ˆ Measures** actual performance improvements to validate impact
5. **ğŸš€ Accelerates** queries by 30-90% on average

### Key Features

- âœ… **Dual-mode support**: Works with Dremio Cloud and on-premises
- âœ… **6+ issue detectors**: Partition pruning, reflections, joins, SELECT *, small files, regressions
- âœ… **AI-powered recommendations**: LangGraph agent with GPT-4o/Claude
- âœ… **SQL rewrites**: Generates optimized SQL automatically
- âœ… **Impact validation**: Tracks before/after metrics
- âœ… **REST API**: FastAPI with 20+ endpoints
- âœ… **Full observability**: OpenTelemetry, Prometheus, Grafana

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- PostgreSQL 15+
- Dremio Cloud or on-premises (v23.0+)
- OpenAI API key or Anthropic API key

### Installation

```bash
# Clone repository
git clone https://github.com/zbelgoumonepoint/dremio_optimizer_agent.git
cd dremio_optimizer_agent

# Install UV (fast Python package manager)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Create virtual environment and install dependencies
uv venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
uv sync
```

### Configuration

```bash
# Copy example configuration
cp .env.example .env

# Edit .env with your settings
nano .env
```

**Required settings**:
```env
# Dremio Configuration
DREMIO_URL=https://api.dremio.cloud  # Or http://localhost:9047
DREMIO_TOKEN=your-personal-access-token
DREMIO_PROJECT_ID=your-project-id  # For Dremio Cloud only

# Database
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/dremio_optimizer

# AI Provider (choose one)
OPENAI_API_KEY=your-openai-key
# ANTHROPIC_API_KEY=your-anthropic-key
```

### Initialize Database

```bash
# Create database
createdb dremio_optimizer

# Run migrations
alembic upgrade head
```

### Test Connection

```bash
python scripts/test_connection.py
```

Expected output:
```
Testing Dremio Connection
============================================================
âœ“ Connected successfully!
âœ“ Successfully fetched recent queries
âœ“ Successfully accessed catalog
âœ“ Successfully accessed reflections
============================================================
```

---

## ğŸ“– Usage

### 1. Collect Data from Dremio

```bash
python scripts/test_collection.py
```

This collects:
- Query history (last 24 hours)
- Execution profiles for slow queries
- Catalog and dataset metadata
- Reflection information

### 2. Analyze Query Performance

```python
from src.services.optimization_service import OptimizationService

service = OptimizationService()

# Analyze a specific query
result = service.optimize_query(job_id="your-job-id")

print(f"Issues detected: {len(result['issues_detected'])}")
print(f"Recommendations: {len(result['recommendations'])}")
```

### 3. View Recommendations

```python
from src.services.recommendation_service import RecommendationService

service = RecommendationService()

# Get all recommendations
recommendations = service.get_recommendations(status="pending", severity="high")

for rec in recommendations:
    print(f"\n{rec['title']}")
    print(f"Estimated improvement: {rec['estimated_improvement_pct']}%")
    print(f"Recommendation: {rec['description']}")
```

### 4. Measure Impact

```python
from src.services.measurement_service import MeasurementService

service = MeasurementService()

# Record before metrics
service.record_before_metrics(recommendation_id=1, job_id="original-job-id")

# ... implement the recommendation and re-run query ...

# Record after metrics
service.record_after_metrics(recommendation_id=1, job_id_after="optimized-job-id")

# View impact
measurement = service.get_measurement(recommendation_id=1)
print(f"Improvement: {measurement['duration_improvement_pct']}%")
print(f"Meets expectation: {measurement['meets_expectation']}")
```

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        DREMIO (Cloud/On-prem)                   â”‚
â”‚                     REST API + System Tables                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ DremioClient (auto-detects mode)
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      DATA COLLECTION LAYER                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚QueryLoader   â”‚  â”‚ProfileLoader  â”‚  â”‚MetadataLoader  â”‚ ...  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                    DremioCollector                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ Repositories (CRUD)
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     POSTGRESQL DATABASE                         â”‚
â”‚    queries | profiles | baselines | recommendations            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       ANALYSIS ENGINE                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚6 Issue Detectors   â”‚  â”‚Baseline System   â”‚                 â”‚
â”‚  â”‚- Partition pruning â”‚  â”‚- Regression det. â”‚                 â”‚
â”‚  â”‚- Reflections       â”‚  â”‚- Signature calc  â”‚                 â”‚
â”‚  â”‚- Join fan-out      â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚  â”‚- SELECT *          â”‚                                         â”‚
â”‚  â”‚- Small files       â”‚                                         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         AI AGENT (LangGraph)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  Tools: Query Analyzer | Reflection Checker |        â”‚      â”‚
â”‚  â”‚         Impact Estimator | SQL Rewriter              â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                    LLM: GPT-4o / Claude                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MEASUREMENT & VALIDATION                     â”‚
â”‚         Before/After Metrics | Impact Calculation              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          REST API (FastAPI)                     â”‚
â”‚      /optimize | /recommendations | /measurements              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ” Detection Capabilities

The system detects **6+ types of performance issues**:

### 1. Partition Pruning Issues
- Detects when queries scan all partitions unnecessarily
- Suggests partition filters to reduce data scanned
- **Typical improvement**: 60-90%

### 2. Reflection Opportunities
- Identifies unused reflections (materialized views)
- Detects missing reflections for common aggregations
- **Typical improvement**: 70-90%

### 3. Join Fan-out
- Detects Cartesian products and join explosions
- Suggests join optimizations and filters
- **Typical improvement**: 40-60%

### 4. SELECT * Anti-pattern
- Identifies queries retrieving unnecessary columns
- Generates column lists based on actual usage
- **Typical improvement**: 15-25%

### 5. Small File Issues
- Detects tables with too many small files
- Recommends compaction strategies
- **Typical improvement**: 50-70%

### 6. Performance Regressions
- Compares query duration to historical baselines
- Flags queries running significantly slower
- **Typical improvement**: 30-80%

---

## ğŸ“Š Example Output

```json
{
  "job_id": "abc-123",
  "analyzed_at": "2026-01-16T10:30:00Z",
  "issues_detected": [
    {
      "issue_type": "missing_partition_filter",
      "severity": "high",
      "title": "Missing Partition Filter on Large Table",
      "description": "Query scans all 365 partitions but WHERE clause doesn't filter on partition column (order_date)",
      "evidence": {
        "partitions_total": 365,
        "partitions_scanned": 365,
        "partition_columns": ["order_date"],
        "pruning_ratio": 0.0
      }
    }
  ],
  "recommendations": [
    {
      "title": "Add Partition Filter on order_date",
      "estimated_improvement_pct": 85,
      "sql_rewrite": "-- Add: WHERE order_date >= CURRENT_DATE - INTERVAL '30' DAY",
      "implementation_steps": [
        "Add WHERE clause filter on order_date",
        "Verify partition pruning in query profile",
        "Consider creating date-based reflection"
      ],
      "agent_reasoning": "Query currently scans all 365 daily partitions (12 months of data)..."
    }
  ],
  "total_estimated_improvement_pct": 85
}
```

---

## ğŸ“š Documentation

### Getting Started
- **[Setup Guide](documentation/SETUP_GUIDE.md)** - Complete installation and configuration
- **[Dremio Cloud Setup](documentation/DREMIO_CLOUD_SETUP.md)** - Cloud-specific configuration
- **[Quick Start](QUICKSTART.md)** - Fast setup for development

### Planning & Architecture
- **[Project Roadmap](planning/PROJECT_ROADMAP.md)** - Complete 7-phase timeline
- **[Phase 1: Foundation](planning/PHASE_1_FOUNDATION.md)** - Data collection (âœ… COMPLETE)
- **[Phase 2: Analysis Engine](planning/PHASE_2_ANALYSIS_ENGINE.md)** - 6 detectors (â³ NEXT)
- **[Phase 3-7 Plans](planning/)** - AI Agent, Measurement, API, Observability, Testing

### Technical Documentation
- **[Data Collection Guide](documentation/DATA_COLLECTION_GUIDE.md)** - What data to collect
- **[Dremio Cloud API Integration](documentation/DREMIO_CLOUD_API_COMPLETE.md)** - API details
- **[SSL Configuration](documentation/SSL_FIX_COMPLETE.md)** - SSL troubleshooting

### API Documentation
- **OpenAPI Docs**: Available at `/docs` when running the API server
- **Redoc**: Available at `/redoc`

---

## ğŸ› ï¸ Development

### Project Structure

```
dremio_optimizer_agent/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/                    # FastAPI routes and schemas
â”‚   â”œâ”€â”€ agents/                 # LangGraph AI agent and tools
â”‚   â”œâ”€â”€ analysis/               # Issue detectors and metrics
â”‚   â”œâ”€â”€ clients/                # Dremio API client
â”‚   â”œâ”€â”€ config/                 # Configuration management
â”‚   â”œâ”€â”€ data/                   # Data loaders and collectors
â”‚   â”œâ”€â”€ database/               # SQLAlchemy models and repositories
â”‚   â”œâ”€â”€ observability/          # Tracing and logging
â”‚   â””â”€â”€ services/               # Business logic services
â”œâ”€â”€ scripts/                    # Utility scripts
â”œâ”€â”€ tests/                      # Test suite
â”œâ”€â”€ documentation/              # Project documentation
â”œâ”€â”€ planning/                   # Phase planning documents
â”œâ”€â”€ alembic/                    # Database migrations
â””â”€â”€ pyproject.toml             # Project dependencies
```

### Running Tests

```bash
# Install dev dependencies
uv sync

# Run all tests
pytest

# Run with coverage
pytest --cov=src --cov-report=html

# Run specific test types
pytest tests/unit/           # Unit tests only
pytest tests/integration/    # Integration tests
pytest tests/e2e/           # End-to-end tests
```

### Code Quality

```bash
# Format code
black src/

# Lint code
ruff check src/

# Type checking
mypy src/
```

### Database Migrations

```bash
# Create new migration
alembic revision --autogenerate -m "Description"

# Apply migrations
alembic upgrade head

# Rollback
alembic downgrade -1
```

---

## ğŸš¦ Current Status

### âœ… Phase 1: Foundation & Data Collection (COMPLETE)

**Delivered**:
- âœ… Dual-mode Dremio client (Cloud + On-prem)
- âœ… PostgreSQL schema with 8 tables
- âœ… 7 specialized data loaders
- âœ… 4 repository classes
- âœ… Configuration system
- âœ… Complete documentation

**Stats**: 60+ files, 4,300+ lines of code

### â³ Phase 2: Analysis Engine (NEXT)

**Planned**:
- 6 issue detectors with evidence collection
- Baseline system for regression detection
- Analysis service orchestration
- Testing and validation

**Estimated Duration**: 1-2 weeks

### ğŸ“‹ Phases 3-7: Planned

- **Phase 3**: AI Agent (LangGraph + GPT-4o)
- **Phase 4**: Performance Measurement
- **Phase 5**: REST API (FastAPI)
- **Phase 6**: Observability (OpenTelemetry + Prometheus)
- **Phase 7**: Testing & Documentation

See [Project Roadmap](planning/PROJECT_ROADMAP.md) for complete timeline.

---

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Development Setup

```bash
# Clone your fork
git clone https://github.com/YOUR_USERNAME/dremio_optimizer_agent.git

# Install with dev dependencies
uv sync

# Run tests
pytest

# Run code quality checks
black src/ && ruff check src/ && mypy src/
```

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Dremio** - For the powerful data lakehouse platform
- **LangChain/LangGraph** - For AI agent framework
- **OpenAI/Anthropic** - For LLM capabilities
- **FastAPI** - For the excellent API framework

---

## ğŸ“ Support

- **GitHub Issues**: [Report bugs or request features](https://github.com/zbelgoumonepoint/dremio_optimizer_agent/issues)
- **Documentation**: [Full documentation](documentation/)
- **Email**: z.belgoum@groupeonepoint.com

---

## ğŸ—ºï¸ Roadmap

### Short-term (Q1 2026)
- [ ] Complete Phase 2 (Analysis Engine)
- [ ] Complete Phase 3 (AI Agent)
- [ ] Initial production deployment

### Mid-term (Q2 2026)
- [ ] REST API with authentication
- [ ] Grafana dashboards
- [ ] Automated recommendation testing
- [ ] Multi-tenant support

### Long-term (H2 2026)
- [ ] Real-time query monitoring
- [ ] Automatic optimization application
- [ ] Cost optimization recommendations
- [ ] Integration with BI tools

---

## ğŸ“ˆ Performance Metrics

Based on initial testing and benchmarks:

| Metric | Target | Status |
|--------|--------|--------|
| Average improvement | >30% | ğŸ¯ On track |
| Detection accuracy | >85% | ğŸ“Š TBD (Phase 2) |
| Recommendation quality | >80% adoption | ğŸ“Š TBD (Phase 3) |
| API response time | <500ms p95 | ğŸ“Š TBD (Phase 5) |
| False positive rate | <15% | ğŸ“Š TBD (Phase 2) |

---

## ğŸ”— Related Projects

- **[Dremio](https://www.dremio.com/)** - Open Data Lakehouse Platform
- **[LangGraph](https://langchain-ai.github.io/langgraph/)** - Framework for building AI agents
- **[Apache Arrow](https://arrow.apache.org/)** - Columnar in-memory analytics

---

<div align="center">

**Built with â¤ï¸ for the Dremio community**

[Report Bug](https://github.com/zbelgoumonepoint/dremio_optimizer_agent/issues) Â·
[Request Feature](https://github.com/zbelgoumonepoint/dremio_optimizer_agent/issues) Â·
[Documentation](documentation/)

</div>
